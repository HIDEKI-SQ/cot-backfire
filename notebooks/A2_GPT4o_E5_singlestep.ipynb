{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2-GPT4o: E5 Single-Step Experiment at c=0.1\n",
    "\n",
    "**Paper**: A2 (Cue-Dominant Extraction)\n",
    "\n",
    "**Purpose**: Replicate E5 (single-step isolation at c=0.1) using GPT-4o to test model generality.\n",
    "\n",
    "**Design**:\n",
    "- Model: GPT-4o\n",
    "- c = 0.1 (single step corrupted)\n",
    "- L = 10\n",
    "- Conditions:\n",
    "  - Step1-Only: Only Step 1 corrupted (cue intact)\n",
    "  - Step10-Only: Only Step 10 corrupted (cue destroyed)\n",
    "\n",
    "**Claude results (for comparison)**:\n",
    "- Step1-Only: 97.0%\n",
    "- Step10-Only: 85.9%\n",
    "- Difference: -11.1 pp\n",
    "- Asymmetry: 22:0\n",
    "\n",
    "**Expected inference count**: 398 (199 × 2 conditions)\n",
    "\n",
    "**Date**: 2026-01-03\n",
    "**GLOBAL_SEED**: 20251224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Drive Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_NAME = 'A2_GPT4o_E5_singlestep'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "V3_DATA_DIR = f'{BASE_DIR}/full_experiment_v3_20251224'\n",
    "\n",
    "SAVE_DIR = f'{BASE_DIR}/{EXPERIMENT_NAME}_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR}/results', exist_ok=True)\n",
    "\n",
    "print(f'Experiment: {EXPERIMENT_NAME}')\n",
    "print(f'V3 data directory: {V3_DATA_DIR}')\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets openai matplotlib pandas tqdm scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional, Any, Set\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# Global Configuration\n",
    "# =============================================================================\n",
    "GLOBAL_SEED = 20251224\n",
    "\n",
    "# Experiment parameters\n",
    "L = 10\n",
    "C_TARGET = 0.1  # Single step\n",
    "\n",
    "# Position configurations\n",
    "STEP1_ONLY = {1}   # First step corrupted, cue intact\n",
    "STEP10_ONLY = {10}  # Last step (cue) corrupted\n",
    "\n",
    "# API settings\n",
    "API_MAX_TOKENS_ANSWER = 256\n",
    "API_RETRY_DELAY = 1.0\n",
    "API_RATE_LIMIT_DELAY = 0.5\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o: E5 SINGLE-STEP EXPERIMENT AT c=0.1')\n",
    "print('='*70)\n",
    "print(f'  Model: GPT-4o')\n",
    "print(f'  GLOBAL_SEED: {GLOBAL_SEED}')\n",
    "print(f'  L (trace length): {L}')\n",
    "print(f'  c (corruption fraction): {C_TARGET}')\n",
    "print(f'  Step1-Only: Step 1 corrupted (cue intact)')\n",
    "print(f'  Step10-Only: Step 10 corrupted (cue destroyed)')\n",
    "print('='*70)\n",
    "print('\\nClaude results (for comparison):')\n",
    "print('  Step1-Only: 97.0%')\n",
    "print('  Step10-Only: 85.9%')\n",
    "print('  Difference: -11.1 pp')\n",
    "print('  Asymmetry: 22:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GSM8KProblem:\n",
    "    index: int\n",
    "    question: str\n",
    "    answer_text: str\n",
    "    final_answer: int\n",
    "\n",
    "@dataclass\n",
    "class CleanTrace:\n",
    "    problem_index: int\n",
    "    I: int\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "\n",
    "@dataclass\n",
    "class SingleStepCorruptedTrace:\n",
    "    problem_index: int\n",
    "    L: int\n",
    "    corrupted_step: int\n",
    "    corruption_type: str\n",
    "    cue_status: str\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "    seed: int\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    problem_index: int\n",
    "    condition: str\n",
    "    model: str\n",
    "    L: int\n",
    "    corrupted_step: int\n",
    "    cue_status: str\n",
    "    model_answer: Optional[int]\n",
    "    correct_answer: int\n",
    "    is_correct: bool\n",
    "    raw_output: str\n",
    "    timestamp: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_seed(global_seed: int, problem_id: int, I: int, lam: float, replicate_id: int = 0) -> int:\n",
    "    key = f\"{global_seed}|{problem_id}|I={I}|lam={lam}|rep={replicate_id}\"\n",
    "    h = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def save_json(data: Any, filepath: str):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_json(filepath: str) -> Any:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_path = f'{V3_DATA_DIR}/problems_v3.json'\n",
    "problems_data = load_json(problems_path)\n",
    "problems = [GSM8KProblem(**p) for p in problems_data]\n",
    "print(f'Loaded {len(problems)} problems')\n",
    "\n",
    "traces_path = f'{V3_DATA_DIR}/clean_traces/clean_traces_I10_v3.json'\n",
    "traces_data = load_json(traces_path)\n",
    "clean_traces = [CleanTrace(**t) for t in traces_data]\n",
    "trace_map = {t.problem_index: t for t in clean_traces}\n",
    "print(f'Loaded {len(clean_traces)} clean traces (L=10)')\n",
    "\n",
    "prob_map = {p.index: p for p in problems}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Corruption Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRRELEVANT_TEMPLATES = [\n",
    "    \"Compute an auxiliary value: aux = {a} + {b} = {result}, but it will not be used later.\",\n",
    "    \"Compute a side quantity: aux = {a} * 2 = {result}, unrelated to the final result.\",\n",
    "    \"Note that we can also compute aux = {a} - {b} = {result}, though this is not needed.\",\n",
    "]\n",
    "\n",
    "WRONG_CONSTRAINT_TEMPLATES = [\n",
    "    \"Fix an intermediate condition: set {var} = {wrong_value} as a given constraint for the rest of the steps.\",\n",
    "    \"Assume the total is {var} = {wrong_value} and proceed using this fixed value.\",\n",
    "]\n",
    "\n",
    "def generate_irrelevant_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    a = rng.randint(2, 20)\n",
    "    b = rng.randint(2, 20)\n",
    "    template = rng.choice(IRRELEVANT_TEMPLATES)\n",
    "    if '+' in template:\n",
    "        result = a + b\n",
    "    elif '*' in template:\n",
    "        result = a * 2\n",
    "    else:\n",
    "        result = a - b\n",
    "    return template.format(a=a, b=b, result=result)\n",
    "\n",
    "def generate_local_error_step(original_step: str, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    numbers = re.findall(r'\\d+', original_step)\n",
    "    if not numbers:\n",
    "        return f\"Compute t = 10 * 3 = {rng.randint(28, 32)} (using the previous values).\"\n",
    "    original_result = int(numbers[-1])\n",
    "    offset = rng.choice([-3, -2, -1, 1, 2, 3])\n",
    "    wrong_result = max(0, original_result + offset)\n",
    "    modified = re.sub(r'= (\\d+)\\.$', f'= {wrong_result}.', original_step)\n",
    "    if modified == original_step:\n",
    "        modified = re.sub(r'(\\d+)\\.$', f'{wrong_result}.', original_step)\n",
    "    return modified\n",
    "\n",
    "def generate_wrong_constraint_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    var = rng.choice(['x', 'total', 'result', 'n'])\n",
    "    wrong_value = rng.randint(10, 100)\n",
    "    template = rng.choice(WRONG_CONSTRAINT_TEMPLATES)\n",
    "    return template.format(var=var, wrong_value=wrong_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single-Step Corruption Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_corruption_type(seed: int) -> str:\n",
    "    \"\"\"Select corruption type with ratio IRR:LOC:WRONG = 1:2:2.\"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    types = ['IRR'] + ['LOC'] * 2 + ['WRONG'] * 2\n",
    "    return rng.choice(types)\n",
    "\n",
    "def create_single_step_corrupted_trace(\n",
    "    clean_trace: CleanTrace,\n",
    "    corrupt_step: int,\n",
    "    seed: int\n",
    ") -> SingleStepCorruptedTrace:\n",
    "    \"\"\"Create trace with only one step corrupted.\"\"\"\n",
    "    L = clean_trace.I\n",
    "    \n",
    "    ctype = select_corruption_type(seed)\n",
    "    step_seed = seed + corrupt_step * 1000\n",
    "    \n",
    "    step_contents = []\n",
    "    for i, step_content in enumerate(clean_trace.steps):\n",
    "        step_num = i + 1\n",
    "        if step_num == corrupt_step:\n",
    "            if ctype == 'IRR':\n",
    "                new_content = generate_irrelevant_step(step_num, step_seed)\n",
    "            elif ctype == 'LOC':\n",
    "                new_content = generate_local_error_step(step_content, step_seed)\n",
    "            else:\n",
    "                new_content = generate_wrong_constraint_step(step_num, step_seed)\n",
    "            step_contents.append(new_content)\n",
    "        else:\n",
    "            step_contents.append(step_content)\n",
    "    \n",
    "    # Determine cue status\n",
    "    cue_status = 'corrupted' if corrupt_step == 10 else 'intact'\n",
    "    \n",
    "    # Build full text\n",
    "    lines = ['[[COT_START]]']\n",
    "    for i, content in enumerate(step_contents):\n",
    "        lines.append(f'Step {i+1}: {content}')\n",
    "    lines.append('[[COT_END]]')\n",
    "    full_text = '\\n'.join(lines)\n",
    "    \n",
    "    return SingleStepCorruptedTrace(\n",
    "        problem_index=clean_trace.problem_index,\n",
    "        L=L,\n",
    "        corrupted_step=corrupt_step,\n",
    "        corruption_type=ctype,\n",
    "        cue_status=cue_status,\n",
    "        steps=step_contents,\n",
    "        full_text=full_text,\n",
    "        seed=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single-step corruption\n",
    "test_trace = clean_traces[0]\n",
    "test_seed = derive_seed(GLOBAL_SEED, test_trace.problem_index, L, C_TARGET)\n",
    "\n",
    "step1_trace = create_single_step_corrupted_trace(test_trace, 1, test_seed)\n",
    "step10_trace = create_single_step_corrupted_trace(test_trace, 10, test_seed)\n",
    "\n",
    "print('Test Single-Step Corruption:')\n",
    "print(f'  Step1-Only: step {step1_trace.corrupted_step}, type {step1_trace.corruption_type}, cue {step1_trace.cue_status}')\n",
    "print(f'  Step10-Only: step {step10_trace.corrupted_step}, type {step10_trace.corruption_type}, cue {step10_trace.cue_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass('Enter OpenAI API Key: ')\n",
    "print('API Key set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "MODEL = 'gpt-4o'\n",
    "\n",
    "def call_gpt4o(system_prompt: str, user_prompt: str, max_tokens: int = 1024, retries: int = 3) -> str:\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                max_tokens=max_tokens,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            time.sleep(API_RATE_LIMIT_DELAY)\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(API_RETRY_DELAY * (attempt + 1))\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "test_response = call_gpt4o(\n",
    "    \"You output ONLY JSON.\",\n",
    "    'Respond with exactly: {\"test\": \"ok\"}',\n",
    "    max_tokens=50\n",
    ")\n",
    "print(f'API test: {test_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_SYSTEM_PROMPT = \"\"\"You are a calculator that outputs ONLY JSON.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Your output MUST start with the character '{'\n",
    "2. Your output MUST be exactly: {\"final\": <number>}\n",
    "3. Replace <number> with an integer (the numerical answer)\n",
    "4. Do NOT write ANY explanation, reasoning, or text before or after the JSON\n",
    "5. Do NOT write \"I need to\" or \"Let me\" or any other words\n",
    "6. ONLY output the JSON object, nothing else\n",
    "\n",
    "CORRECT OUTPUT EXAMPLE:\n",
    "{\"final\": 42}\n",
    "\"\"\"\n",
    "\n",
    "def create_experiment_prompt(problem: GSM8KProblem, cot_text: str) -> Tuple[str, str]:\n",
    "    user = f\"\"\"Problem: {problem.question}\n",
    "\n",
    "Reasoning trace (use these steps as given facts):\n",
    "{cot_text}\n",
    "\n",
    "Based on the trace above, compute the final numerical answer.\n",
    "OUTPUT ONLY: {{\"final\": <number>}}\n",
    "START YOUR RESPONSE WITH '{{'\"\"\"\n",
    "    return EXPERIMENT_SYSTEM_PROMPT, user\n",
    "\n",
    "def parse_model_answer(response: str) -> Optional[int]:\n",
    "    match = re.search(r'\\{\\s*\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r\"\\{\\s*[\\\"']final[\\\"']\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}\", response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r'\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    matches = re.findall(r'(?:^|\\s)(-?\\d+(?:\\.\\d+)?)(?:\\s|$|\\.|,)', response)\n",
    "    if matches:\n",
    "        return int(round(float(matches[-1])))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    problem: GSM8KProblem,\n",
    "    cot_text: str,\n",
    "    condition: str,\n",
    "    L: int,\n",
    "    corrupted_step: int,\n",
    "    cue_status: str\n",
    ") -> ExperimentResult:\n",
    "    sys_prompt, usr_prompt = create_experiment_prompt(problem, cot_text)\n",
    "    response = call_gpt4o(sys_prompt, usr_prompt, max_tokens=API_MAX_TOKENS_ANSWER)\n",
    "    \n",
    "    model_answer = parse_model_answer(response)\n",
    "    is_correct = (model_answer == problem.final_answer) if model_answer is not None else False\n",
    "    \n",
    "    return ExperimentResult(\n",
    "        problem_index=problem.index,\n",
    "        condition=condition,\n",
    "        model=MODEL,\n",
    "        L=L,\n",
    "        corrupted_step=corrupted_step,\n",
    "        cue_status=cue_status,\n",
    "        model_answer=model_answer,\n",
    "        correct_answer=problem.final_answer,\n",
    "        is_correct=is_correct,\n",
    "        raw_output=response,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('A2-GPT4o: E5 SINGLE-STEP EXPERIMENT (c=0.1)')\n",
    "print('='*70)\n",
    "print(f'Model: {MODEL}')\n",
    "print(f'Conditions: Step1-Only (cue intact), Step10-Only (cue corrupted)')\n",
    "print(f'Expected inferences: {len(problems) * 2}')\n",
    "print('='*70)\n",
    "\n",
    "results_step1 = []\n",
    "results_step10 = []\n",
    "traces_log = []\n",
    "\n",
    "for prob in tqdm(problems, desc='E5 GPT-4o (Step1 + Step10)'):\n",
    "    if prob.index not in trace_map:\n",
    "        continue\n",
    "    \n",
    "    clean_trace = trace_map[prob.index]\n",
    "    seed = derive_seed(GLOBAL_SEED, prob.index, L, C_TARGET)\n",
    "    \n",
    "    # Condition 1: Step1-Only (cue intact)\n",
    "    step1_trace = create_single_step_corrupted_trace(clean_trace, 1, seed)\n",
    "    result_step1 = run_experiment(prob, step1_trace.full_text, 'step1_only', L, 1, 'intact')\n",
    "    results_step1.append(result_step1)\n",
    "    \n",
    "    # Condition 2: Step10-Only (cue corrupted)\n",
    "    step10_trace = create_single_step_corrupted_trace(clean_trace, 10, seed)\n",
    "    result_step10 = run_experiment(prob, step10_trace.full_text, 'step10_only', L, 10, 'corrupted')\n",
    "    results_step10.append(result_step10)\n",
    "    \n",
    "    # Log traces\n",
    "    traces_log.append({\n",
    "        'problem_index': prob.index,\n",
    "        'step1_only': asdict(step1_trace),\n",
    "        'step10_only': asdict(step10_trace)\n",
    "    })\n",
    "\n",
    "print(f'\\nCompleted: {len(results_step1) + len(results_step10)} experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = results_step1 + results_step10\n",
    "save_json([asdict(r) for r in all_results], f'{SAVE_DIR}/results/A2_GPT4o_E5_results.json')\n",
    "print(f'Results saved: {SAVE_DIR}/results/A2_GPT4o_E5_results.json')\n",
    "\n",
    "save_json(traces_log, f'{SAVE_DIR}/results/A2_GPT4o_E5_traces.json')\n",
    "print(f'Traces saved: {SAVE_DIR}/results/A2_GPT4o_E5_traces.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step1 = pd.DataFrame([asdict(r) for r in results_step1])\n",
    "df_step10 = pd.DataFrame([asdict(r) for r in results_step10])\n",
    "\n",
    "step1_acc = df_step1['is_correct'].mean()\n",
    "step10_acc = df_step10['is_correct'].mean()\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o E5 RESULTS (c=0.1)')\n",
    "print('='*70)\n",
    "print(f'Step1-Only (cue intact):    {step1_acc:.1%} ({df_step1[\"is_correct\"].sum()}/{len(df_step1)})')\n",
    "print(f'Step10-Only (cue corrupted): {step10_acc:.1%} ({df_step10[\"is_correct\"].sum()}/{len(df_step10)})')\n",
    "print(f'Difference:                  {(step10_acc - step1_acc)*100:+.1f} pp')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McNemar's test and asymmetry analysis\n",
    "N = len(results_step1)\n",
    "both_correct = sum(1 for i in range(N) if results_step1[i].is_correct and results_step10[i].is_correct)\n",
    "step1_only_correct = sum(1 for i in range(N) if results_step1[i].is_correct and not results_step10[i].is_correct)\n",
    "step10_only_correct = sum(1 for i in range(N) if not results_step1[i].is_correct and results_step10[i].is_correct)\n",
    "both_wrong = sum(1 for i in range(N) if not results_step1[i].is_correct and not results_step10[i].is_correct)\n",
    "\n",
    "print('\\nContingency Table:')\n",
    "print('                    Step10-Only')\n",
    "print('                    Correct  Wrong')\n",
    "print(f'Step1-Only Correct   {both_correct:3d}     {step1_only_correct:3d}')\n",
    "print(f'           Wrong     {step10_only_correct:3d}     {both_wrong:3d}')\n",
    "print(f'\\n*** ASYMMETRY: {step1_only_correct}:{step10_only_correct} ***')\n",
    "print(f'(Claude was 22:0)')\n",
    "\n",
    "if step1_only_correct + step10_only_correct > 0:\n",
    "    chi2 = (abs(step1_only_correct - step10_only_correct) - 1)**2 / (step1_only_correct + step10_only_correct)\n",
    "    p_value = 1 - stats.chi2.cdf(chi2, 1)\n",
    "    print(f'\\nMcNemar χ² = {chi2:.2f}, P = {p_value:.6f}')\n",
    "else:\n",
    "    chi2 = None\n",
    "    p_value = None\n",
    "    print('\\nNo discordant pairs for McNemar test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with Claude\n",
    "claude_step1 = 97.0\n",
    "claude_step10 = 85.9\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('COMPARISON: Claude vs GPT-4o (E5, c=0.1)')\n",
    "print('='*70)\n",
    "print(f'{\"Condition\":<25} {\"Claude\":>12} {\"GPT-4o\":>12}')\n",
    "print('-'*55)\n",
    "print(f'{\"Step1-Only (cue intact)\":<25} {claude_step1:>11.1f}% {step1_acc*100:>11.1f}%')\n",
    "print(f'{\"Step10-Only (cue corrupt)\":<25} {claude_step10:>11.1f}% {step10_acc*100:>11.1f}%')\n",
    "print(f'{\"Difference\":<25} {claude_step10-claude_step1:>+11.1f}pp {(step10_acc-step1_acc)*100:>+11.1f}pp')\n",
    "print(f'{\"Asymmetry\":<25} {\"22:0\":>12} {f\"{step1_only_correct}:{step10_only_correct}\":>12}')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nINTERPRETATION:')\n",
    "if step1_only_correct > step10_only_correct * 2:\n",
    "    print(f'✓ Strong asymmetry: Cue corruption uniquely harmful')\n",
    "    print(f'✓ First step is dispensable for GPT-4o')\n",
    "    print('→ Cue-dominant extraction confirmed for GPT-4o')\n",
    "elif step1_only_correct > step10_only_correct:\n",
    "    print(f'△ Moderate asymmetry: Cue is more important than first step')\n",
    "    print(f'△ Effect may be weaker in GPT-4o than Claude')\n",
    "else:\n",
    "    print(f'✗ No asymmetry or reverse pattern')\n",
    "    print(f'✗ GPT-4o may process traces differently from Claude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'experiment': 'A2_GPT4o_E5_singlestep',\n",
    "    'model': MODEL,\n",
    "    'date': EXPERIMENT_DATE,\n",
    "    'n_problems': N,\n",
    "    'c': C_TARGET,\n",
    "    'L': L,\n",
    "    'results': {\n",
    "        'step1_accuracy': step1_acc,\n",
    "        'step10_accuracy': step10_acc,\n",
    "        'difference_pp': (step10_acc - step1_acc) * 100\n",
    "    },\n",
    "    'mcnemar': {\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value\n",
    "    },\n",
    "    'contingency': {\n",
    "        'both_correct': both_correct,\n",
    "        'step1_only_correct': step1_only_correct,\n",
    "        'step10_only_correct': step10_only_correct,\n",
    "        'both_wrong': both_wrong,\n",
    "        'asymmetry': f'{step1_only_correct}:{step10_only_correct}'\n",
    "    },\n",
    "    'comparison_claude': {\n",
    "        'step1': claude_step1,\n",
    "        'step10': claude_step10,\n",
    "        'difference': claude_step10 - claude_step1,\n",
    "        'asymmetry': '22:0'\n",
    "    }\n",
    "}\n",
    "\n",
    "save_json(summary, f'{SAVE_DIR}/results/A2_GPT4o_E5_summary.json')\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o E5 EXPERIMENT COMPLETE')\n",
    "print('='*70)\n",
    "print(f'Date: {EXPERIMENT_DATE}')\n",
    "print(f'Model: {MODEL}')\n",
    "print(f'Total experiments: {len(all_results)}')\n",
    "print(f'\\nResults:')\n",
    "print(f'  Step1-Only (cue intact):   {step1_acc:.1%}')\n",
    "print(f'  Step10-Only (cue corrupt): {step10_acc:.1%}')\n",
    "print(f'  Difference:                {(step10_acc-step1_acc)*100:+.1f} pp')\n",
    "print(f'  Asymmetry:                 {step1_only_correct}:{step10_only_correct}')\n",
    "print(f'\\nFiles saved to: {SAVE_DIR}')\n",
    "print('='*70)"
   ]
  }
 ]
}
