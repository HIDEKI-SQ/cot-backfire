{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2-GPT4o: E4' Cue Protection Experiment at c=0.4\n",
    "\n",
    "**Paper**: A2 (Cue-Dominant Extraction)\n",
    "\n",
    "**Purpose**: Replicate E4' (cue protection at c=0.4) using GPT-4o to test model generality.\n",
    "\n",
    "**Design**:\n",
    "- Model: GPT-4o\n",
    "- c = 0.4\n",
    "- L = 10\n",
    "- Conditions:\n",
    "  - E2-Late: Steps 7-10 corrupted (cue destroyed)\n",
    "  - E4': Steps 6-9 corrupted, Step 10 protected (cue intact)\n",
    "\n",
    "**Claude results (for comparison)**:\n",
    "- E2-Late (cue corrupted): 60.3%\n",
    "- E4' (cue protected): 92.0%\n",
    "- Cue protection effect: +31.7 pp\n",
    "\n",
    "**Expected inference count**: 398 (199 × 2 conditions)\n",
    "\n",
    "**Date**: 2026-01-03\n",
    "**GLOBAL_SEED**: 20251224\n",
    "\n",
    "---\n",
    "**Note**: This notebook includes rate limit handling for OpenAI API (30k TPM limit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Drive Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_NAME = 'A2_GPT4o_E4prime_cue'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "V3_DATA_DIR = f'{BASE_DIR}/full_experiment_v3_20251224'\n",
    "\n",
    "SAVE_DIR = f'{BASE_DIR}/{EXPERIMENT_NAME}_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR}/results', exist_ok=True)\n",
    "\n",
    "print(f'Experiment: {EXPERIMENT_NAME}')\n",
    "print(f'V3 data directory: {V3_DATA_DIR}')\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets openai matplotlib pandas tqdm scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional, Any, Set\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# =============================================================================\n",
    "# Global Configuration\n",
    "# =============================================================================\n",
    "GLOBAL_SEED = 20251224\n",
    "\n",
    "# Experiment parameters\n",
    "L = 10\n",
    "C_TARGET = 0.4\n",
    "\n",
    "# Position configurations\n",
    "E2_LATE_POSITIONS = {7, 8, 9, 10}  # Cue (Step 10) corrupted\n",
    "E4_PRIME_POSITIONS = {6, 7, 8, 9}  # Cue (Step 10) protected\n",
    "\n",
    "# Corruption type ratio\n",
    "CORRUPTION_RATIO = {'IRR': 1, 'LOC': 2, 'WRONG': 2}\n",
    "\n",
    "# =============================================================================\n",
    "# API settings - Rate limit aware (OpenAI: 30k TPM for gpt-4o)\n",
    "# =============================================================================\n",
    "API_MAX_TOKENS_ANSWER = 256\n",
    "API_RETRY_DELAY = 2.0           # Base retry delay (seconds)\n",
    "API_RATE_LIMIT_DELAY = 2.0      # Delay between API calls (seconds)\n",
    "API_MAX_RETRIES = 5             # Maximum retry attempts\n",
    "API_RATE_LIMIT_WAIT = 60        # Wait time on rate limit (seconds)\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o: E4\\' CUE PROTECTION EXPERIMENT AT c=0.4')\n",
    "print('='*70)\n",
    "print(f'  Model: GPT-4o')\n",
    "print(f'  GLOBAL_SEED: {GLOBAL_SEED}')\n",
    "print(f'  L (trace length): {L}')\n",
    "print(f'  c (corruption fraction): {C_TARGET}')\n",
    "print(f'  E2-Late positions: {sorted(E2_LATE_POSITIONS)} (cue corrupted)')\n",
    "print(f'  E4\\' positions: {sorted(E4_PRIME_POSITIONS)} (cue protected)')\n",
    "print('-'*70)\n",
    "print(f'  API_RATE_LIMIT_DELAY: {API_RATE_LIMIT_DELAY}s')\n",
    "print(f'  API_MAX_RETRIES: {API_MAX_RETRIES}')\n",
    "print(f'  API_RATE_LIMIT_WAIT: {API_RATE_LIMIT_WAIT}s')\n",
    "print('='*70)\n",
    "print('\\nClaude results (for comparison):')\n",
    "print('  E2-Late (cue corrupted): 60.3%')\n",
    "print('  E4\\' (cue protected): 92.0%')\n",
    "print('  Cue protection effect: +31.7 pp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GSM8KProblem:\n",
    "    index: int\n",
    "    question: str\n",
    "    answer_text: str\n",
    "    final_answer: int\n",
    "\n",
    "@dataclass\n",
    "class CleanTrace:\n",
    "    problem_index: int\n",
    "    I: int\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "\n",
    "@dataclass\n",
    "class PositionalCorruptedTrace:\n",
    "    problem_index: int\n",
    "    L: int\n",
    "    c: float\n",
    "    corrupted_positions: List[int]\n",
    "    corruption_types: Dict[int, str]\n",
    "    cue_status: str  # 'corrupted' or 'protected'\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "    seed: int\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    problem_index: int\n",
    "    condition: str\n",
    "    model: str\n",
    "    L: int\n",
    "    c: float\n",
    "    K_clean: int\n",
    "    cue_status: str\n",
    "    model_answer: Optional[int]\n",
    "    correct_answer: int\n",
    "    is_correct: bool\n",
    "    raw_output: str\n",
    "    timestamp: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_seed(global_seed: int, problem_id: int, I: int, lam: float, replicate_id: int = 0) -> int:\n",
    "    key = f\"{global_seed}|{problem_id}|I={I}|lam={lam}|rep={replicate_id}\"\n",
    "    h = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def save_json(data: Any, filepath: str):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_json(filepath: str) -> Any:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_path = f'{V3_DATA_DIR}/problems_v3.json'\n",
    "problems_data = load_json(problems_path)\n",
    "problems = [GSM8KProblem(**p) for p in problems_data]\n",
    "print(f'Loaded {len(problems)} problems')\n",
    "\n",
    "traces_path = f'{V3_DATA_DIR}/clean_traces/clean_traces_I10_v3.json'\n",
    "traces_data = load_json(traces_path)\n",
    "clean_traces = [CleanTrace(**t) for t in traces_data]\n",
    "trace_map = {t.problem_index: t for t in clean_traces}\n",
    "print(f'Loaded {len(clean_traces)} clean traces (L=10)')\n",
    "\n",
    "prob_map = {p.index: p for p in problems}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Corruption Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRRELEVANT_TEMPLATES = [\n",
    "    \"Compute an auxiliary value: aux = {a} + {b} = {result}, but it will not be used later.\",\n",
    "    \"Compute a side quantity: aux = {a} * 2 = {result}, unrelated to the final result.\",\n",
    "    \"Note that we can also compute aux = {a} - {b} = {result}, though this is not needed.\",\n",
    "]\n",
    "\n",
    "WRONG_CONSTRAINT_TEMPLATES = [\n",
    "    \"Fix an intermediate condition: set {var} = {wrong_value} as a given constraint for the rest of the steps.\",\n",
    "    \"Assume the total is {var} = {wrong_value} and proceed using this fixed value.\",\n",
    "]\n",
    "\n",
    "def generate_irrelevant_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    a = rng.randint(2, 20)\n",
    "    b = rng.randint(2, 20)\n",
    "    template = rng.choice(IRRELEVANT_TEMPLATES)\n",
    "    if '+' in template:\n",
    "        result = a + b\n",
    "    elif '*' in template:\n",
    "        result = a * 2\n",
    "    else:\n",
    "        result = a - b\n",
    "    return template.format(a=a, b=b, result=result)\n",
    "\n",
    "def generate_local_error_step(original_step: str, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    numbers = re.findall(r'\\d+', original_step)\n",
    "    if not numbers:\n",
    "        return f\"Compute t = 10 * 3 = {rng.randint(28, 32)} (using the previous values).\"\n",
    "    original_result = int(numbers[-1])\n",
    "    offset = rng.choice([-3, -2, -1, 1, 2, 3])\n",
    "    wrong_result = max(0, original_result + offset)\n",
    "    modified = re.sub(r'= (\\d+)\\.$', f'= {wrong_result}.', original_step)\n",
    "    if modified == original_step:\n",
    "        modified = re.sub(r'(\\d+)\\.$', f'{wrong_result}.', original_step)\n",
    "    return modified\n",
    "\n",
    "def generate_wrong_constraint_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    var = rng.choice(['x', 'total', 'result', 'n'])\n",
    "    wrong_value = rng.randint(10, 100)\n",
    "    template = rng.choice(WRONG_CONSTRAINT_TEMPLATES)\n",
    "    return template.format(var=var, wrong_value=wrong_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Positional Corruption Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_corruption_types_positional(positions: Set[int], seed: int) -> Dict[int, str]:\n",
    "    \"\"\"Assign corruption types to specific positions.\"\"\"\n",
    "    K = len(positions)\n",
    "    if K == 0:\n",
    "        return {}\n",
    "    \n",
    "    n_irr = (K * 1) // 5\n",
    "    n_loc = (K * 2) // 5\n",
    "    n_wrong = K - n_irr - n_loc\n",
    "    \n",
    "    if n_wrong == 0 and K > 0:\n",
    "        n_wrong = 1\n",
    "        if n_loc > 0:\n",
    "            n_loc -= 1\n",
    "        elif n_irr > 0:\n",
    "            n_irr -= 1\n",
    "    \n",
    "    rng = random.Random(seed + 1)\n",
    "    perm = list(positions)\n",
    "    rng.shuffle(perm)\n",
    "    \n",
    "    type_map = {}\n",
    "    for s in perm[:n_irr]:\n",
    "        type_map[s] = \"IRR\"\n",
    "    for s in perm[n_irr:n_irr + n_loc]:\n",
    "        type_map[s] = \"LOC\"\n",
    "    for s in perm[n_irr + n_loc:]:\n",
    "        type_map[s] = \"WRONG\"\n",
    "    \n",
    "    return type_map\n",
    "\n",
    "def create_positional_corrupted_trace(\n",
    "    clean_trace: CleanTrace,\n",
    "    corrupt_positions: Set[int],\n",
    "    seed: int,\n",
    "    cue_status: str\n",
    ") -> PositionalCorruptedTrace:\n",
    "    \"\"\"Create trace with corruption at specific positions.\"\"\"\n",
    "    L = clean_trace.I\n",
    "    c = len(corrupt_positions) / L\n",
    "    \n",
    "    corruption_types = assign_corruption_types_positional(corrupt_positions, seed)\n",
    "    \n",
    "    step_contents = []\n",
    "    for i, step_content in enumerate(clean_trace.steps):\n",
    "        step_num = i + 1\n",
    "        if step_num in corruption_types:\n",
    "            ctype = corruption_types[step_num]\n",
    "            step_seed = seed + step_num * 1000\n",
    "            if ctype == 'IRR':\n",
    "                new_content = generate_irrelevant_step(step_num, step_seed)\n",
    "            elif ctype == 'LOC':\n",
    "                new_content = generate_local_error_step(step_content, step_seed)\n",
    "            else:\n",
    "                new_content = generate_wrong_constraint_step(step_num, step_seed)\n",
    "            step_contents.append(new_content)\n",
    "        else:\n",
    "            step_contents.append(step_content)\n",
    "    \n",
    "    # Build full text\n",
    "    lines = ['[[COT_START]]']\n",
    "    for i, content in enumerate(step_contents):\n",
    "        lines.append(f'Step {i+1}: {content}')\n",
    "    lines.append('[[COT_END]]')\n",
    "    full_text = '\\n'.join(lines)\n",
    "    \n",
    "    return PositionalCorruptedTrace(\n",
    "        problem_index=clean_trace.problem_index,\n",
    "        L=L,\n",
    "        c=c,\n",
    "        corrupted_positions=sorted(list(corrupt_positions)),\n",
    "        corruption_types=corruption_types,\n",
    "        cue_status=cue_status,\n",
    "        steps=step_contents,\n",
    "        full_text=full_text,\n",
    "        seed=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test positional corruption\n",
    "test_trace = clean_traces[0]\n",
    "test_seed = derive_seed(GLOBAL_SEED, test_trace.problem_index, L, C_TARGET)\n",
    "\n",
    "e2_late = create_positional_corrupted_trace(test_trace, E2_LATE_POSITIONS, test_seed, 'corrupted')\n",
    "e4_prime = create_positional_corrupted_trace(test_trace, E4_PRIME_POSITIONS, test_seed, 'protected')\n",
    "\n",
    "print('Test Positional Corruption:')\n",
    "print(f'  E2-Late positions: {e2_late.corrupted_positions} (cue {e2_late.cue_status})')\n",
    "print(f'  E4\\' positions: {e4_prime.corrupted_positions} (cue {e4_prime.cue_status})')\n",
    "print(f'  E2-Late types: {e2_late.corruption_types}')\n",
    "print(f'  E4\\' types: {e4_prime.corruption_types}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. API Setup (Rate Limit Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass('Enter OpenAI API Key: ')\n",
    "print('API Key set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "MODEL = 'gpt-4o'\n",
    "\n",
    "def call_gpt4o(\n",
    "    system_prompt: str, \n",
    "    user_prompt: str, \n",
    "    max_tokens: int = 1024, \n",
    "    retries: int = API_MAX_RETRIES\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call GPT-4o API with robust rate limit handling.\n",
    "    \n",
    "    Rate limit strategy:\n",
    "    - Normal delay between calls: API_RATE_LIMIT_DELAY seconds\n",
    "    - On rate limit error: exponential backoff with longer waits\n",
    "    - Max retries: API_MAX_RETRIES\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                max_tokens=max_tokens,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            # Normal delay between successful calls\n",
    "            time.sleep(API_RATE_LIMIT_DELAY)\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            print(f'API error (attempt {attempt+1}/{retries}): {e}')\n",
    "            \n",
    "            # Check if it's a rate limit error\n",
    "            if '429' in error_str or 'rate_limit' in error_str.lower():\n",
    "                # Exponential backoff for rate limits\n",
    "                if attempt == 0:\n",
    "                    wait_time = 10  # First retry: 10 seconds\n",
    "                elif attempt == 1:\n",
    "                    wait_time = 30  # Second retry: 30 seconds\n",
    "                else:\n",
    "                    wait_time = API_RATE_LIMIT_WAIT  # 60 seconds\n",
    "                \n",
    "                print(f'  → Rate limit hit, waiting {wait_time}s before retry...')\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # Other errors: shorter backoff\n",
    "                if attempt < retries - 1:\n",
    "                    wait_time = API_RETRY_DELAY * (attempt + 1)\n",
    "                    print(f'  → Waiting {wait_time}s before retry...')\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    raise\n",
    "    \n",
    "    # If all retries exhausted\n",
    "    raise Exception(f'API call failed after {retries} attempts')\n",
    "\n",
    "# Test API\n",
    "print('Testing API connection...')\n",
    "test_response = call_gpt4o(\n",
    "    \"You output ONLY JSON.\",\n",
    "    'Respond with exactly: {\"test\": \"ok\"}',\n",
    "    max_tokens=50\n",
    ")\n",
    "print(f'API test successful: {test_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_SYSTEM_PROMPT = \"\"\"You are a calculator that outputs ONLY JSON.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Your output MUST start with the character '{'\n",
    "2. Your output MUST be exactly: {\"final\": <number>}\n",
    "3. Replace <number> with an integer (the numerical answer)\n",
    "4. Do NOT write ANY explanation, reasoning, or text before or after the JSON\n",
    "5. Do NOT write \"I need to\" or \"Let me\" or any other words\n",
    "6. ONLY output the JSON object, nothing else\n",
    "\n",
    "CORRECT OUTPUT EXAMPLE:\n",
    "{\"final\": 42}\n",
    "\"\"\"\n",
    "\n",
    "def create_experiment_prompt(problem: GSM8KProblem, cot_text: str) -> Tuple[str, str]:\n",
    "    user = f\"\"\"Problem: {problem.question}\n",
    "\n",
    "Reasoning trace (use these steps as given facts):\n",
    "{cot_text}\n",
    "\n",
    "Based on the trace above, compute the final numerical answer.\n",
    "OUTPUT ONLY: {{\"final\": <number>}}\n",
    "START YOUR RESPONSE WITH '{{'\"\"\"\n",
    "    return EXPERIMENT_SYSTEM_PROMPT, user\n",
    "\n",
    "def parse_model_answer(response: str) -> Optional[int]:\n",
    "    match = re.search(r'\\{\\s*\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r\"\\{\\s*[\\\"']final[\\\"']\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}\", response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r'\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    matches = re.findall(r'(?:^|\\s)(-?\\d+(?:\\.\\d+)?)(?:\\s|$|\\.|,)', response)\n",
    "    if matches:\n",
    "        return int(round(float(matches[-1])))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    problem: GSM8KProblem,\n",
    "    cot_text: str,\n",
    "    condition: str,\n",
    "    L: int,\n",
    "    c: float,\n",
    "    cue_status: str\n",
    ") -> ExperimentResult:\n",
    "    sys_prompt, usr_prompt = create_experiment_prompt(problem, cot_text)\n",
    "    response = call_gpt4o(sys_prompt, usr_prompt, max_tokens=API_MAX_TOKENS_ANSWER)\n",
    "    \n",
    "    model_answer = parse_model_answer(response)\n",
    "    is_correct = (model_answer == problem.final_answer) if model_answer is not None else False\n",
    "    \n",
    "    K_clean = L - int(round(c * L))\n",
    "    \n",
    "    return ExperimentResult(\n",
    "        problem_index=problem.index,\n",
    "        condition=condition,\n",
    "        model=MODEL,\n",
    "        L=L,\n",
    "        c=c,\n",
    "        K_clean=K_clean,\n",
    "        cue_status=cue_status,\n",
    "        model_answer=model_answer,\n",
    "        correct_answer=problem.final_answer,\n",
    "        is_correct=is_correct,\n",
    "        raw_output=response,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('A2-GPT4o: E4\\' CUE PROTECTION EXPERIMENT (c=0.4)')\n",
    "print('='*70)\n",
    "print(f'Model: {MODEL}')\n",
    "print(f'Conditions: E2-Late (cue corrupted), E4\\' (cue protected)')\n",
    "print(f'Expected inferences: {len(problems) * 2}')\n",
    "print(f'Estimated time: ~{len(problems) * 2 * API_RATE_LIMIT_DELAY / 60:.1f} minutes (without rate limits)')\n",
    "print('='*70)\n",
    "\n",
    "results_e2_late = []\n",
    "results_e4_prime = []\n",
    "traces_log = []\n",
    "\n",
    "# Track progress for potential resume\n",
    "start_idx = 0  # Change this if resuming from a specific index\n",
    "\n",
    "for idx, prob in enumerate(tqdm(problems[start_idx:], desc='E4\\' GPT-4o', initial=start_idx, total=len(problems))):\n",
    "    if prob.index not in trace_map:\n",
    "        continue\n",
    "    \n",
    "    clean_trace = trace_map[prob.index]\n",
    "    seed = derive_seed(GLOBAL_SEED, prob.index, L, C_TARGET)\n",
    "    \n",
    "    try:\n",
    "        # Condition 1: E2-Late (cue corrupted)\n",
    "        e2_late_trace = create_positional_corrupted_trace(clean_trace, E2_LATE_POSITIONS, seed, 'corrupted')\n",
    "        result_e2_late = run_experiment(prob, e2_late_trace.full_text, 'e2_late', L, C_TARGET, 'corrupted')\n",
    "        results_e2_late.append(result_e2_late)\n",
    "        \n",
    "        # Condition 2: E4' (cue protected)\n",
    "        e4_prime_trace = create_positional_corrupted_trace(clean_trace, E4_PRIME_POSITIONS, seed, 'protected')\n",
    "        result_e4_prime = run_experiment(prob, e4_prime_trace.full_text, 'e4_prime', L, C_TARGET, 'protected')\n",
    "        results_e4_prime.append(result_e4_prime)\n",
    "        \n",
    "        # Log traces\n",
    "        traces_log.append({\n",
    "            'problem_index': prob.index,\n",
    "            'e2_late': asdict(e2_late_trace),\n",
    "            'e4_prime': asdict(e4_prime_trace)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\nFatal error at problem {prob.index}: {e}')\n",
    "        print(f'Progress: {len(results_e2_late)} problems completed')\n",
    "        print(f'To resume, set start_idx = {idx + start_idx} and re-run this cell')\n",
    "        break\n",
    "\n",
    "print(f'\\nCompleted: {len(results_e2_late)} + {len(results_e4_prime)} = {len(results_e2_late) + len(results_e4_prime)} experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = results_e2_late + results_e4_prime\n",
    "save_json([asdict(r) for r in all_results], f'{SAVE_DIR}/results/A2_GPT4o_E4prime_results.json')\n",
    "print(f'Results saved: {SAVE_DIR}/results/A2_GPT4o_E4prime_results.json')\n",
    "\n",
    "save_json(traces_log, f'{SAVE_DIR}/results/A2_GPT4o_E4prime_traces.json')\n",
    "print(f'Traces saved: {SAVE_DIR}/results/A2_GPT4o_E4prime_traces.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e2_late = pd.DataFrame([asdict(r) for r in results_e2_late])\n",
    "df_e4_prime = pd.DataFrame([asdict(r) for r in results_e4_prime])\n",
    "\n",
    "e2_late_acc = df_e2_late['is_correct'].mean()\n",
    "e4_prime_acc = df_e4_prime['is_correct'].mean()\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o E4\\' RESULTS (c=0.4)')\n",
    "print('='*70)\n",
    "print(f'E2-Late (cue corrupted):  {e2_late_acc:.1%} ({df_e2_late[\"is_correct\"].sum()}/{len(df_e2_late)})')\n",
    "print(f'E4\\' (cue protected):     {e4_prime_acc:.1%} ({df_e4_prime[\"is_correct\"].sum()}/{len(df_e4_prime)})')\n",
    "print(f'Cue protection effect:    {(e4_prime_acc - e2_late_acc)*100:+.1f} pp')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McNemar's test\n",
    "N = len(results_e2_late)\n",
    "both_correct = sum(1 for i in range(N) if results_e2_late[i].is_correct and results_e4_prime[i].is_correct)\n",
    "e2_only = sum(1 for i in range(N) if results_e2_late[i].is_correct and not results_e4_prime[i].is_correct)\n",
    "e4_only = sum(1 for i in range(N) if not results_e2_late[i].is_correct and results_e4_prime[i].is_correct)\n",
    "both_wrong = sum(1 for i in range(N) if not results_e2_late[i].is_correct and not results_e4_prime[i].is_correct)\n",
    "\n",
    "print('\\nContingency Table:')\n",
    "print('                    E4\\' (cue protected)')\n",
    "print('                    Correct  Wrong')\n",
    "print(f'E2-Late   Correct    {both_correct:3d}     {e2_only:3d}')\n",
    "print(f'(corrupt) Wrong      {e4_only:3d}     {both_wrong:3d}')\n",
    "print(f'\\nAsymmetry: {e4_only}:{e2_only}')\n",
    "\n",
    "if e2_only + e4_only > 0:\n",
    "    chi2 = (abs(e2_only - e4_only) - 1)**2 / (e2_only + e4_only)\n",
    "    p_value = 1 - stats.chi2.cdf(chi2, 1)\n",
    "    print(f'McNemar χ² = {chi2:.2f}, P = {p_value:.6f}')\n",
    "else:\n",
    "    chi2 = None\n",
    "    p_value = None\n",
    "    print('No discordant pairs for McNemar test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with Claude\n",
    "claude_e2_late = 60.3\n",
    "claude_e4_prime = 92.0\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('COMPARISON: Claude vs GPT-4o (E4\\', c=0.4)')\n",
    "print('='*70)\n",
    "print(f'{\"Condition\":<25} {\"Claude\":>12} {\"GPT-4o\":>12}')\n",
    "print('-'*55)\n",
    "print(f'{\"E2-Late (cue corrupt)\":<25} {claude_e2_late:>11.1f}% {e2_late_acc*100:>11.1f}%')\n",
    "print(f'{\"E4\\' (cue protected)\":<25} {claude_e4_prime:>11.1f}% {e4_prime_acc*100:>11.1f}%')\n",
    "print(f'{\"Cue protection effect\":<25} {claude_e4_prime-claude_e2_late:>+11.1f}pp {(e4_prime_acc-e2_late_acc)*100:>+11.1f}pp')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nINTERPRETATION:')\n",
    "cue_effect = (e4_prime_acc - e2_late_acc) * 100\n",
    "if cue_effect > 20:\n",
    "    print(f'✓ GPT-4o: Strong cue protection effect ({cue_effect:+.1f} pp)')\n",
    "    print('✓ Cue-dominant extraction confirmed for GPT-4o')\n",
    "    print('→ Finding generalizes across models')\n",
    "elif cue_effect > 10:\n",
    "    print(f'△ GPT-4o: Moderate cue protection effect ({cue_effect:+.1f} pp)')\n",
    "    print('△ Weaker than Claude but still present')\n",
    "else:\n",
    "    print(f'✗ GPT-4o: Weak cue protection effect ({cue_effect:+.1f} pp)')\n",
    "    print('✗ Model-specific processing strategies may exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'experiment': 'A2_GPT4o_E4prime_cue',\n",
    "    'model': MODEL,\n",
    "    'date': EXPERIMENT_DATE,\n",
    "    'n_problems': N,\n",
    "    'c': C_TARGET,\n",
    "    'L': L,\n",
    "    'positions': {\n",
    "        'e2_late': list(E2_LATE_POSITIONS),\n",
    "        'e4_prime': list(E4_PRIME_POSITIONS)\n",
    "    },\n",
    "    'results': {\n",
    "        'e2_late_accuracy': e2_late_acc,\n",
    "        'e4_prime_accuracy': e4_prime_acc,\n",
    "        'cue_protection_effect_pp': (e4_prime_acc - e2_late_acc) * 100\n",
    "    },\n",
    "    'mcnemar': {\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value\n",
    "    },\n",
    "    'contingency': {\n",
    "        'both_correct': both_correct,\n",
    "        'e2_late_only': e2_only,\n",
    "        'e4_prime_only': e4_only,\n",
    "        'both_wrong': both_wrong,\n",
    "        'asymmetry': f'{e4_only}:{e2_only}'\n",
    "    },\n",
    "    'comparison_claude': {\n",
    "        'e2_late': claude_e2_late,\n",
    "        'e4_prime': claude_e4_prime,\n",
    "        'effect': claude_e4_prime - claude_e2_late\n",
    "    },\n",
    "    'api_settings': {\n",
    "        'rate_limit_delay': API_RATE_LIMIT_DELAY,\n",
    "        'max_retries': API_MAX_RETRIES,\n",
    "        'rate_limit_wait': API_RATE_LIMIT_WAIT\n",
    "    }\n",
    "}\n",
    "\n",
    "save_json(summary, f'{SAVE_DIR}/results/A2_GPT4o_E4prime_summary.json')\n",
    "\n",
    "print('='*70)\n",
    "print('A2-GPT4o E4\\' EXPERIMENT COMPLETE')\n",
    "print('='*70)\n",
    "print(f'Date: {EXPERIMENT_DATE}')\n",
    "print(f'Model: {MODEL}')\n",
    "print(f'Total experiments: {len(all_results)}')\n",
    "print(f'\\nResults:')\n",
    "print(f'  E2-Late (cue corrupt): {e2_late_acc:.1%}')\n",
    "print(f'  E4\\' (cue protected):  {e4_prime_acc:.1%}')\n",
    "print(f'  Cue protection effect: {(e4_prime_acc-e2_late_acc)*100:+.1f} pp')\n",
    "print(f'\\nFiles saved to: {SAVE_DIR}')\n",
    "print('='*70)"
   ]
  }
 ]
}
