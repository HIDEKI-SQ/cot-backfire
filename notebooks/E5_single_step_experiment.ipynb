{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5: Single-Step Corruption Experiment - Direct Test of Answer-Cue Importance\n",
    "\n",
    "**Paper**: A2 (Redundancy vs Depth in CoT Length Effects)\n",
    "\n",
    "**Purpose**: Most direct test of whether Step 10 (Final cue) is uniquely important.\n",
    "\n",
    "**Sofia's suggestion**: Step10 only vs Step1 only is the most direct test.\n",
    "If Step10-only causes failure while Step1-only does not, E2/E3 effects are explained.\n",
    "\n",
    "**Design**:\n",
    "- c = 0.1 (only 1 step corrupted out of 10)\n",
    "- L = 10\n",
    "- **Step1-Only**: Corrupt ONLY Step 1\n",
    "- **Step10-Only**: Corrupt ONLY Step 10 (Final cue)\n",
    "\n",
    "**Predictions**:\n",
    "- Step1-Only: High accuracy (first step is dispensable)\n",
    "- Step10-Only: Low accuracy (Final cue destroyed)\n",
    "- If Step10-Only << Step1-Only -> Answer-cue dominance confirmed\n",
    "\n",
    "**Expected inference count**: 199 x 2 = 398\n",
    "\n",
    "**Date**: 2025-01-02\n",
    "\n",
    "**GLOBAL_SEED**: 20251224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Drive Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_NAME = 'E5_single_step'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "V3_DATA_DIR = f'{BASE_DIR}/full_experiment_v3_20251224'\n",
    "\n",
    "SAVE_DIR = f'{BASE_DIR}/{EXPERIMENT_NAME}_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR}/results', exist_ok=True)\n",
    "\n",
    "print(f'Experiment: {EXPERIMENT_NAME}')\n",
    "print(f'V3 data directory: {V3_DATA_DIR}')\n",
    "print(f'Save directory: {SAVE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets anthropic matplotlib pandas tqdm scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# Global Configuration\n",
    "# =============================================================================\n",
    "GLOBAL_SEED = 20251224\n",
    "E5_SEED = 20250102\n",
    "\n",
    "# Experiment parameters\n",
    "L = 10\n",
    "C_TARGET = 0.1  # Only 1 step corrupted\n",
    "\n",
    "# API settings\n",
    "API_MAX_TOKENS_ANSWER = 256\n",
    "API_RETRY_DELAY = 1.0\n",
    "API_RATE_LIMIT_DELAY = 0.5\n",
    "\n",
    "print('='*70)\n",
    "print('E5: SINGLE-STEP CORRUPTION EXPERIMENT')\n",
    "print('='*70)\n",
    "print(f'  GLOBAL_SEED: {GLOBAL_SEED}')\n",
    "print(f'  L (trace length): {L}')\n",
    "print(f'  c (corruption fraction): {C_TARGET}')\n",
    "print(f'  Conditions:')\n",
    "print(f'    - Step1-Only: Corrupt ONLY Step 1')\n",
    "print(f'    - Step10-Only: Corrupt ONLY Step 10 (Final cue)')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GSM8KProblem:\n",
    "    index: int\n",
    "    question: str\n",
    "    answer_text: str\n",
    "    final_answer: int\n",
    "\n",
    "@dataclass\n",
    "class CleanTrace:\n",
    "    problem_index: int\n",
    "    I: int\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "\n",
    "@dataclass\n",
    "class SingleStepTrace:\n",
    "    problem_index: int\n",
    "    L: int\n",
    "    condition: str  # 'step1_only' or 'step10_only'\n",
    "    corrupted_step: int\n",
    "    corruption_type: str\n",
    "    final_cue_clean: bool\n",
    "    steps: List[str]\n",
    "    full_text: str\n",
    "    seed: int\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    problem_index: int\n",
    "    condition: str\n",
    "    L: int\n",
    "    corrupted_step: int\n",
    "    corruption_type: str\n",
    "    final_cue_clean: bool\n",
    "    model_answer: Optional[int]\n",
    "    correct_answer: int\n",
    "    is_correct: bool\n",
    "    raw_output: str\n",
    "    timestamp: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_seed(global_seed: int, problem_id: int, L: int, extra: str = '') -> int:\n",
    "    key = f\"{global_seed}|{problem_id}|L={L}|{extra}\"\n",
    "    h = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def save_json(data: Any, filepath: str):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_json(filepath: str) -> Any:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_path = f'{V3_DATA_DIR}/problems_v3.json'\n",
    "problems_data = load_json(problems_path)\n",
    "problems = [GSM8KProblem(**p) for p in problems_data]\n",
    "print(f'Loaded {len(problems)} problems')\n",
    "\n",
    "traces_path = f'{V3_DATA_DIR}/clean_traces/clean_traces_I10_v3.json'\n",
    "traces_data = load_json(traces_path)\n",
    "clean_traces = [CleanTrace(**t) for t in traces_data]\n",
    "trace_map = {t.problem_index: t for t in clean_traces}\n",
    "print(f'Loaded {len(clean_traces)} clean traces (L=10)')\n",
    "\n",
    "prob_map = {p.index: p for p in problems}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Corruption Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single-step corruption, we use WRONG type (most harmful)\n",
    "# This maximizes the chance of detecting the effect\n",
    "\n",
    "WRONG_CONSTRAINT_TEMPLATES = [\n",
    "    \"Fix an intermediate condition: set {var} = {wrong_value} as a given constraint for the rest of the steps.\",\n",
    "    \"Assume the total is {var} = {wrong_value} and proceed using this fixed value.\",\n",
    "]\n",
    "\n",
    "def generate_wrong_constraint_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    var = rng.choice(['x', 'total', 'result', 'n'])\n",
    "    wrong_value = rng.randint(10, 100)\n",
    "    template = rng.choice(WRONG_CONSTRAINT_TEMPLATES)\n",
    "    return template.format(var=var, wrong_value=wrong_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single-Step Corruption Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_step_trace(\n",
    "    clean_trace: CleanTrace,\n",
    "    target_step: int,  # 1 or 10\n",
    "    seed: int\n",
    ") -> SingleStepTrace:\n",
    "    \"\"\"\n",
    "    Create a trace with ONLY one step corrupted.\n",
    "    \n",
    "    - target_step=1: Corrupt Step 1 only (first step)\n",
    "    - target_step=10: Corrupt Step 10 only (Final cue)\n",
    "    \"\"\"\n",
    "    L = clean_trace.I\n",
    "    condition = f'step{target_step}_only'\n",
    "    corruption_type = 'WRONG'  # Use WRONG for maximum effect\n",
    "    \n",
    "    # Apply corruption to single step\n",
    "    new_steps = []\n",
    "    for i, step_content in enumerate(clean_trace.steps):\n",
    "        step_num = i + 1\n",
    "        if step_num == target_step:\n",
    "            # Corrupt this step\n",
    "            step_seed = seed + step_num * 1000\n",
    "            new_content = generate_wrong_constraint_step(step_num, step_seed)\n",
    "            new_steps.append(new_content)\n",
    "        else:\n",
    "            # Keep clean\n",
    "            new_steps.append(step_content)\n",
    "    \n",
    "    # Build full text\n",
    "    lines = ['[[COT_START]]']\n",
    "    for i, content in enumerate(new_steps):\n",
    "        lines.append(f'Step {i+1}: {content}')\n",
    "    lines.append('[[COT_END]]')\n",
    "    full_text = '\\n'.join(lines)\n",
    "    \n",
    "    # Final cue is clean if target is NOT step 10\n",
    "    final_cue_clean = (target_step != 10)\n",
    "    \n",
    "    return SingleStepTrace(\n",
    "        problem_index=clean_trace.problem_index,\n",
    "        L=L,\n",
    "        condition=condition,\n",
    "        corrupted_step=target_step,\n",
    "        corruption_type=corruption_type,\n",
    "        final_cue_clean=final_cue_clean,\n",
    "        steps=new_steps,\n",
    "        full_text=full_text,\n",
    "        seed=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single-step logic\n",
    "test_trace = clean_traces[0]\n",
    "\n",
    "# Step 1 only\n",
    "step1_trace = create_single_step_trace(test_trace, 1, E5_SEED)\n",
    "print('Step1-Only Trace:')\n",
    "print(f'  Corrupted step: {step1_trace.corrupted_step}')\n",
    "print(f'  Final cue clean: {step1_trace.final_cue_clean}')\n",
    "print(f'  Step 1: {step1_trace.steps[0][:80]}...')\n",
    "print(f'  Step 10: {step1_trace.steps[9][:80]}...')\n",
    "\n",
    "# Step 10 only\n",
    "step10_trace = create_single_step_trace(test_trace, 10, E5_SEED)\n",
    "print('\\nStep10-Only Trace:')\n",
    "print(f'  Corrupted step: {step10_trace.corrupted_step}')\n",
    "print(f'  Final cue clean: {step10_trace.final_cue_clean}')\n",
    "print(f'  Step 1: {step10_trace.steps[0][:80]}...')\n",
    "print(f'  Step 10: {step10_trace.steps[9][:80]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "ANTHROPIC_API_KEY = getpass('Enter Anthropic API Key: ')\n",
    "print('API Key set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "def call_claude(system_prompt: str, user_prompt: str, max_tokens: int = 1024, retries: int = 3) -> str:\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            message = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=max_tokens,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "                system=system_prompt,\n",
    "                temperature=0\n",
    "            )\n",
    "            time.sleep(API_RATE_LIMIT_DELAY)\n",
    "            return message.content[0].text\n",
    "        except Exception as e:\n",
    "            print(f'API error (attempt {attempt+1}): {e}')\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(API_RETRY_DELAY * (attempt + 1))\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "test_response = call_claude(\n",
    "    \"You output ONLY JSON.\",\n",
    "    'Respond with exactly: {\"test\": \"ok\"}',\n",
    "    max_tokens=50\n",
    ")\n",
    "print(f'API test: {test_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_SYSTEM_PROMPT = \"\"\"You are a calculator that outputs ONLY JSON.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Your output MUST start with the character '{'\n",
    "2. Your output MUST be exactly: {\"final\": <number>}\n",
    "3. Replace <number> with an integer (the numerical answer)\n",
    "4. Do NOT write ANY explanation, reasoning, or text before or after the JSON\n",
    "5. Do NOT write \"I need to\" or \"Let me\" or any other words\n",
    "6. ONLY output the JSON object, nothing else\n",
    "\n",
    "CORRECT OUTPUT EXAMPLE:\n",
    "{\"final\": 42}\n",
    "\"\"\"\n",
    "\n",
    "def create_experiment_prompt(problem: GSM8KProblem, cot_text: str) -> Tuple[str, str]:\n",
    "    user = f\"\"\"Problem: {problem.question}\n",
    "\n",
    "Reasoning trace (use these steps as given facts):\n",
    "{cot_text}\n",
    "\n",
    "Based on the trace above, compute the final numerical answer.\n",
    "OUTPUT ONLY: {{\"final\": <number>}}\n",
    "START YOUR RESPONSE WITH '{{'\"\"\"\n",
    "    return EXPERIMENT_SYSTEM_PROMPT, user\n",
    "\n",
    "def parse_model_answer(response: str) -> Optional[int]:\n",
    "    match = re.search(r'\\{\\s*\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r\"\\{\\s*[\\\"']final[\\\"']\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*\\}\", response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    match = re.search(r'\"final\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)', response)\n",
    "    if match:\n",
    "        return int(round(float(match.group(1))))\n",
    "    matches = re.findall(r'(?:^|\\s)(-?\\d+(?:\\.\\d+)?)(?:\\s|$|\\.|,)', response)\n",
    "    if matches:\n",
    "        return int(round(float(matches[-1])))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    problem: GSM8KProblem,\n",
    "    trace: SingleStepTrace\n",
    ") -> ExperimentResult:\n",
    "    sys_prompt, usr_prompt = create_experiment_prompt(problem, trace.full_text)\n",
    "    response = call_claude(sys_prompt, usr_prompt, max_tokens=API_MAX_TOKENS_ANSWER)\n",
    "    \n",
    "    model_answer = parse_model_answer(response)\n",
    "    is_correct = (model_answer == problem.final_answer) if model_answer is not None else False\n",
    "    \n",
    "    return ExperimentResult(\n",
    "        problem_index=problem.index,\n",
    "        condition=trace.condition,\n",
    "        L=trace.L,\n",
    "        corrupted_step=trace.corrupted_step,\n",
    "        corruption_type=trace.corruption_type,\n",
    "        final_cue_clean=trace.final_cue_clean,\n",
    "        model_answer=model_answer,\n",
    "        correct_answer=problem.final_answer,\n",
    "        is_correct=is_correct,\n",
    "        raw_output=response,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('E5: SINGLE-STEP CORRUPTION EXPERIMENT')\n",
    "print('='*70)\n",
    "print(f'Conditions: Step1-Only, Step10-Only')\n",
    "print(f'Expected inferences: {len(problems) * 2}')\n",
    "print('='*70)\n",
    "\n",
    "results_step1 = []\n",
    "results_step10 = []\n",
    "traces_log = []\n",
    "\n",
    "for prob in tqdm(problems, desc='Single-step experiment'):\n",
    "    if prob.index not in trace_map:\n",
    "        continue\n",
    "    \n",
    "    clean_trace = trace_map[prob.index]\n",
    "    \n",
    "    # Step 1 only condition\n",
    "    seed1 = derive_seed(E5_SEED, prob.index, L, 'step1_only')\n",
    "    trace_step1 = create_single_step_trace(clean_trace, 1, seed1)\n",
    "    traces_log.append(asdict(trace_step1))\n",
    "    result_step1 = run_experiment(prob, trace_step1)\n",
    "    results_step1.append(result_step1)\n",
    "    \n",
    "    # Step 10 only condition\n",
    "    seed10 = derive_seed(E5_SEED, prob.index, L, 'step10_only')\n",
    "    trace_step10 = create_single_step_trace(clean_trace, 10, seed10)\n",
    "    traces_log.append(asdict(trace_step10))\n",
    "    result_step10 = run_experiment(prob, trace_step10)\n",
    "    results_step10.append(result_step10)\n",
    "\n",
    "print(f'\\nCompleted: {len(results_step1)} Step1-Only + {len(results_step10)} Step10-Only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = results_step1 + results_step10\n",
    "save_json([asdict(r) for r in all_results], f'{SAVE_DIR}/results/E5_single_step_results.json')\n",
    "print(f'Results saved: {SAVE_DIR}/results/E5_single_step_results.json')\n",
    "\n",
    "save_json(traces_log, f'{SAVE_DIR}/results/E5_single_step_traces.json')\n",
    "print(f'Traces saved: {SAVE_DIR}/results/E5_single_step_traces.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_step1 = pd.DataFrame([asdict(r) for r in results_step1])\n",
    "df_step10 = pd.DataFrame([asdict(r) for r in results_step10])\n",
    "\n",
    "step1_acc = df_step1['is_correct'].mean()\n",
    "step10_acc = df_step10['is_correct'].mean()\n",
    "\n",
    "print('='*70)\n",
    "print('E5 RESULTS')\n",
    "print('='*70)\n",
    "print(f'{\"Condition\":<25} {\"Accuracy\":>10} {\"N\":>6} {\"Final cue\":>12}')\n",
    "print('-'*55)\n",
    "print(f'{\"Step1-Only\":<25} {step1_acc:>9.1%} {len(df_step1):>6} {\"CLEAN\":>12}')\n",
    "print(f'{\"Step10-Only\":<25} {step10_acc:>9.1%} {len(df_step10):>6} {\"CORRUPTED\":>12}')\n",
    "print('-'*55)\n",
    "print(f'Difference (Step10 - Step1): {step10_acc - step1_acc:+.1%}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# McNemar's test\n",
    "merged = pd.merge(\n",
    "    df_step1[['problem_index', 'is_correct']].rename(columns={'is_correct': 'step1'}),\n",
    "    df_step10[['problem_index', 'is_correct']].rename(columns={'is_correct': 'step10'}),\n",
    "    on='problem_index'\n",
    ")\n",
    "\n",
    "a = ((merged['step1'] == True) & (merged['step10'] == True)).sum()\n",
    "b = ((merged['step1'] == True) & (merged['step10'] == False)).sum()\n",
    "c = ((merged['step1'] == False) & (merged['step10'] == True)).sum()\n",
    "d = ((merged['step1'] == False) & (merged['step10'] == False)).sum()\n",
    "\n",
    "print('\\nContingency Table:')\n",
    "print(f'  Both correct: {a}')\n",
    "print(f'  Step1 only correct: {b}')\n",
    "print(f'  Step10 only correct: {c}')\n",
    "print(f'  Both wrong: {d}')\n",
    "\n",
    "if b + c > 0:\n",
    "    chi2 = (abs(b - c) - 1)**2 / (b + c)\n",
    "    p_value = 1 - stats.chi2.cdf(chi2, df=1)\n",
    "    print(f'\\nMcNemar test: chi2 = {chi2:.2f}, p = {p_value:.6f}')\n",
    "    \n",
    "    if p_value < 0.001:\n",
    "        print('*** Highly significant (p < 0.001)')\n",
    "    elif p_value < 0.01:\n",
    "        print('** Significant (p < 0.01)')\n",
    "    elif p_value < 0.05:\n",
    "        print('* Significant (p < 0.05)')\n",
    "    else:\n",
    "        print('Not significant (p >= 0.05)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "print('\\n' + '='*70)\n",
    "print('INTERPRETATION')\n",
    "print('='*70)\n",
    "\n",
    "if step1_acc > step10_acc + 0.20:\n",
    "    print('RESULT: Step1-Only >> Step10-Only')\n",
    "    print('CONCLUSION: ANSWER-CUE DOMINANCE CONFIRMED')\n",
    "    print('')\n",
    "    print('Corrupting Step 1 (first step) has minimal impact.')\n",
    "    print('Corrupting Step 10 (Final cue) is catastrophic.')\n",
    "    print('')\n",
    "    print('This directly proves:')\n",
    "    print('  1. The model relies heavily on Step 10 (Final=...)')\n",
    "    print('  2. Earlier steps are dispensable (redundant)')\n",
    "    print('  3. E2/E3 effects are due to Final cue destruction,')\n",
    "    print('     NOT sequential chain integration (depth)')\n",
    "elif step1_acc > step10_acc + 0.10:\n",
    "    print('RESULT: Step1-Only > Step10-Only')\n",
    "    print('  Partial support for answer-cue dominance.')\n",
    "else:\n",
    "    print('RESULT: Unexpected')\n",
    "    print('  Need further investigation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('E5 EXPERIMENT COMPLETE')\n",
    "print('='*70)\n",
    "print(f'Date: {EXPERIMENT_DATE}')\n",
    "print(f'Total experiments: {len(all_results)}')\n",
    "print(f'Step1-Only accuracy: {step1_acc:.1%}')\n",
    "print(f'Step10-Only accuracy: {step10_acc:.1%}')\n",
    "print(f'Difference: {step1_acc - step10_acc:+.1%}')\n",
    "print(f'\\nFiles saved to: {SAVE_DIR}')\n",
    "print('='*70)"
   ]
  }
 ]
}
