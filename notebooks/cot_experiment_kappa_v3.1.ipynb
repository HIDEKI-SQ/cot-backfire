{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoT Phase Transition Experiment v3.1 - Curvature (κ) Measurement\n",
    "\n",
    "**Version**: 3.1 (2024-12-24)\n",
    "\n",
    "**Changes from v3.0**:\n",
    "- Changed model from Llama 3 8B to **Mistral 7B** (no authentication required)\n",
    "- Works with T4 GPU (A100 not required)\n",
    "\n",
    "**Purpose**: Measure hidden state trajectory curvature (κ) to geometrically validate CoT collapse.\n",
    "\n",
    "**Design**:\n",
    "- Model: Mistral 7B v0.1 (open-weight, NO authentication needed)\n",
    "- Conditions: Direct / Standard CoT (A=1.0) / Corrupted CoT (A=0.2)\n",
    "- Layers: L/2, 3L/4, L (3 layers)\n",
    "- Measurement: Online curvature computation along CoT token range\n",
    "\n",
    "**Hypothesis**:\n",
    "- Successful CoT → Low κ (smooth trajectory)\n",
    "- Corrupted CoT → High κ (jagged trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Drive Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_VERSION = 'v3.1'\n",
    "EXPERIMENT_DATE = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# 実験1のディレクトリを探す\n",
    "SAVE_DIR = '/content/drive/MyDrive/CoT_Experiment'\n",
    "\n",
    "# 実験1のclean tracesがあるディレクトリを特定\n",
    "exp1_dirs = [d for d in os.listdir(SAVE_DIR) if d.startswith('full_experiment_v3')]\n",
    "if exp1_dirs:\n",
    "    EXP1_DIR = f'{SAVE_DIR}/{sorted(exp1_dirs)[-1]}'\n",
    "else:\n",
    "    EXP1_DIR = f'{SAVE_DIR}/pilot_v2'\n",
    "\n",
    "print(f'Experiment 1 directory: {EXP1_DIR}')\n",
    "\n",
    "# 実験2の保存先\n",
    "SAVE_DIR_KAPPA = f'{SAVE_DIR}/kappa_experiment_{EXPERIMENT_VERSION}_{EXPERIMENT_DATE}'\n",
    "os.makedirs(SAVE_DIR_KAPPA, exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_KAPPA}/results', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_KAPPA}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{SAVE_DIR_KAPPA}/figures', exist_ok=True)\n",
    "\n",
    "print(f'Kappa experiment save directory: {SAVE_DIR_KAPPA}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f'\\nPyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate bitsandbytes datasets matplotlib seaborn pandas tqdm scipy -q\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "import hashlib\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "GLOBAL_SEED = 20251224\n",
    "\n",
    "# Mistral 7B - NO AUTHENTICATION REQUIRED\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# κ計算の定数（仕様パック準拠）\n",
    "EPSILON = 1e-8\n",
    "DELTA = 1e-6\n",
    "\n",
    "# 条件\n",
    "CONDITIONS = ['direct', 'clean', 'corrupted']\n",
    "CORRUPTION_LAMBDA = 0.8\n",
    "\n",
    "# チェックポイント\n",
    "CHECKPOINT_EVERY = 20\n",
    "\n",
    "print('='*60)\n",
    "print('KAPPA EXPERIMENT CONFIGURATION')\n",
    "print('='*60)\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Conditions: {CONDITIONS}')\n",
    "print(f'  Corruption λ: {CORRUPTION_LAMBDA}')\n",
    "print('  NOTE: No authentication required for Mistral!')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model (Mistral 7B - No Auth Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print('Loading model (this may take a few minutes)...')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    output_hidden_states=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# モデル情報\n",
    "NUM_LAYERS = model.config.num_hidden_layers\n",
    "HIDDEN_DIM = model.config.hidden_size\n",
    "\n",
    "print(f'\\nModel loaded successfully!')\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Layers: {NUM_LAYERS}')\n",
    "print(f'  Hidden dim: {HIDDEN_DIM}')\n",
    "\n",
    "# 測定する層を決定（仕様パック準拠：L/2, 3L/4, L）\n",
    "MEASURE_LAYERS = [\n",
    "    NUM_LAYERS // 2,\n",
    "    (3 * NUM_LAYERS) // 4,\n",
    "    NUM_LAYERS\n",
    "]\n",
    "print(f'  Measurement layers: {MEASURE_LAYERS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Clean Traces from Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filepath: str) -> Any:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, filepath: str):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Clean traces (I=10) を読み込む\n",
    "clean_traces_path = f'{EXP1_DIR}/clean_traces/clean_traces_I10_v3.json'\n",
    "if not os.path.exists(clean_traces_path):\n",
    "    clean_traces_path = f'{EXP1_DIR}/clean_traces_I10.json'\n",
    "if not os.path.exists(clean_traces_path):\n",
    "    # ルートディレクトリも探す\n",
    "    for root, dirs, files in os.walk(SAVE_DIR):\n",
    "        for f in files:\n",
    "            if 'clean_traces_I10' in f and f.endswith('.json'):\n",
    "                clean_traces_path = os.path.join(root, f)\n",
    "                break\n",
    "\n",
    "print(f'Loading clean traces from: {clean_traces_path}')\n",
    "clean_traces_data = load_json(clean_traces_path)\n",
    "print(f'Loaded {len(clean_traces_data)} clean traces')\n",
    "\n",
    "# 問題データも読み込む\n",
    "problems_path = f'{EXP1_DIR}/problems_v3.json'\n",
    "if not os.path.exists(problems_path):\n",
    "    problems_path = f'{EXP1_DIR}/pilot_problems.json'\n",
    "if not os.path.exists(problems_path):\n",
    "    for root, dirs, files in os.walk(SAVE_DIR):\n",
    "        for f in files:\n",
    "            if 'problems' in f and f.endswith('.json'):\n",
    "                problems_path = os.path.join(root, f)\n",
    "                break\n",
    "\n",
    "print(f'Loading problems from: {problems_path}')\n",
    "problems_data = load_json(problems_path)\n",
    "print(f'Loaded {len(problems_data)} problems')\n",
    "\n",
    "# 辞書に変換\n",
    "problems_dict = {p['index']: p for p in problems_data}\n",
    "traces_dict = {t['problem_index']: t for t in clean_traces_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class KappaResult:\n",
    "    problem_index: int\n",
    "    condition: str\n",
    "    kappa_by_layer: Dict[int, float]\n",
    "    kappa_mean: float\n",
    "    n_tokens: int\n",
    "    timestamp: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Corruption Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_seed(global_seed: int, problem_id: int, I: int, lam: float, replicate_id: int = 0) -> int:\n",
    "    key = f\"{global_seed}|{problem_id}|I={I}|lam={lam}|rep={replicate_id}\"\n",
    "    h = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def pick_corrupted_steps(I: int, lam: float, seed: int) -> List[int]:\n",
    "    K = int(round(lam * I))\n",
    "    if K == 0:\n",
    "        return []\n",
    "    steps = list(range(1, I + 1))\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(steps)\n",
    "    return sorted(steps[:K])\n",
    "\n",
    "def assign_corruption_types(corrupted_steps: List[int], seed: int) -> Dict[int, str]:\n",
    "    K = len(corrupted_steps)\n",
    "    if K == 0:\n",
    "        return {}\n",
    "    n_irr = (K * 1) // 5\n",
    "    n_loc = (K * 2) // 5\n",
    "    n_wrong = K - n_irr - n_loc\n",
    "    if n_wrong == 0 and K > 0:\n",
    "        n_wrong = 1\n",
    "        if n_loc > 0:\n",
    "            n_loc -= 1\n",
    "        elif n_irr > 0:\n",
    "            n_irr -= 1\n",
    "    rng = random.Random(seed + 1)\n",
    "    perm = corrupted_steps[:]\n",
    "    rng.shuffle(perm)\n",
    "    type_map = {}\n",
    "    for s in perm[:n_irr]:\n",
    "        type_map[s] = \"IRR\"\n",
    "    for s in perm[n_irr:n_irr + n_loc]:\n",
    "        type_map[s] = \"LOC\"\n",
    "    for s in perm[n_irr + n_loc:]:\n",
    "        type_map[s] = \"WRONG\"\n",
    "    return type_map\n",
    "\n",
    "IRRELEVANT_TEMPLATES = [\n",
    "    \"Compute an auxiliary value: aux = {a} + {b} = {result}, but it will not be used later.\",\n",
    "]\n",
    "\n",
    "WRONG_CONSTRAINT_TEMPLATES = [\n",
    "    \"Fix an intermediate condition: set {var} = {wrong_value} as a given constraint for the rest of the steps.\",\n",
    "]\n",
    "\n",
    "def generate_irrelevant_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    a, b = rng.randint(2, 20), rng.randint(2, 20)\n",
    "    return IRRELEVANT_TEMPLATES[0].format(a=a, b=b, result=a+b)\n",
    "\n",
    "def generate_local_error_step(original_step: str, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    numbers = re.findall(r'\\d+', original_step)\n",
    "    if not numbers:\n",
    "        return f\"Compute t = 10 * 3 = {rng.randint(28, 32)} (using the previous values).\"\n",
    "    original_result = int(numbers[-1])\n",
    "    offset = rng.choice([-3, -2, -1, 1, 2, 3])\n",
    "    wrong_result = max(0, original_result + offset)\n",
    "    modified = re.sub(r'= (\\d+)\\.$', f'= {wrong_result}.', original_step)\n",
    "    if modified == original_step:\n",
    "        modified = re.sub(r'(\\d+)\\.$', f'{wrong_result}.', original_step)\n",
    "    return modified\n",
    "\n",
    "def generate_wrong_constraint_step(step_num: int, seed: int) -> str:\n",
    "    rng = random.Random(seed)\n",
    "    var = rng.choice(['x', 'total', 'result', 'n'])\n",
    "    wrong_value = rng.randint(10, 100)\n",
    "    return WRONG_CONSTRAINT_TEMPLATES[0].format(var=var, wrong_value=wrong_value)\n",
    "\n",
    "def apply_corruption(trace_data: dict, lam: float, seed: int) -> str:\n",
    "    steps = trace_data['steps'][:]\n",
    "    I = len(steps)\n",
    "    corrupted_steps = pick_corrupted_steps(I, lam, seed)\n",
    "    corruption_types = assign_corruption_types(corrupted_steps, seed)\n",
    "    new_steps = []\n",
    "    for i, step_content in enumerate(steps):\n",
    "        step_num = i + 1\n",
    "        if step_num in corruption_types:\n",
    "            ctype = corruption_types[step_num]\n",
    "            step_seed = seed + step_num * 1000\n",
    "            if ctype == 'IRR':\n",
    "                new_content = generate_irrelevant_step(step_num, step_seed)\n",
    "            elif ctype == 'LOC':\n",
    "                new_content = generate_local_error_step(step_content, step_seed)\n",
    "            else:\n",
    "                new_content = generate_wrong_constraint_step(step_num, step_seed)\n",
    "            new_steps.append(new_content)\n",
    "        else:\n",
    "            new_steps.append(step_content)\n",
    "    lines = ['[[COT_START]]']\n",
    "    for i, content in enumerate(new_steps):\n",
    "        lines.append(f'Step {i+1}: {content}')\n",
    "    lines.append('[[COT_END]]')\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "print('Corruption logic defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prompt Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_direct(problem: dict) -> str:\n",
    "    return f\"\"\"Problem: {problem['question']}\n",
    "\n",
    "Compute the final numerical answer.\n",
    "Answer:\"\"\"\n",
    "\n",
    "def create_prompt_with_cot(problem: dict, cot_text: str) -> str:\n",
    "    return f\"\"\"Problem: {problem['question']}\n",
    "\n",
    "Reasoning trace:\n",
    "{cot_text}\n",
    "\n",
    "Based on the trace above, compute the final numerical answer.\n",
    "Answer:\"\"\"\n",
    "\n",
    "print('Prompt functions defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Curvature (κ) Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cot_token_range(input_ids: torch.Tensor, tokenizer) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    [[COT_START]] と [[COT_END]] の間のトークン範囲を特定する。\n",
    "    \"\"\"\n",
    "    text = tokenizer.decode(input_ids[0])\n",
    "    start_marker = '[[COT_START]]'\n",
    "    end_marker = '[[COT_END]]'\n",
    "    \n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    if start_pos == -1 or end_pos == -1:\n",
    "        return 0, input_ids.shape[1]\n",
    "    \n",
    "    # 文字位置からトークン位置への近似変換\n",
    "    tokens_before_start = tokenizer.encode(text[:start_pos + len(start_marker)], add_special_tokens=False)\n",
    "    start_token_idx = len(tokens_before_start)\n",
    "    \n",
    "    tokens_before_end = tokenizer.encode(text[:end_pos], add_special_tokens=False)\n",
    "    end_token_idx = len(tokens_before_end)\n",
    "    \n",
    "    # 安全のためクリップ\n",
    "    start_token_idx = max(0, min(start_token_idx, input_ids.shape[1] - 3))\n",
    "    end_token_idx = max(start_token_idx + 3, min(end_token_idx, input_ids.shape[1]))\n",
    "    \n",
    "    return start_token_idx, end_token_idx\n",
    "\n",
    "\n",
    "def compute_curvature_online(hidden_states: torch.Tensor, eps: float = EPSILON, delta: float = DELTA) -> float:\n",
    "    \"\"\"\n",
    "    オンラインでκ（曲率）を計算する（仕様パック準拠）。\n",
    "    \"\"\"\n",
    "    T = hidden_states.shape[0]\n",
    "    if T < 3:\n",
    "        return float('nan')\n",
    "    \n",
    "    total_angle = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    prev = hidden_states[0]\n",
    "    curr = hidden_states[1]\n",
    "    v_prev = curr - prev\n",
    "    \n",
    "    for t in range(2, T):\n",
    "        nxt = hidden_states[t]\n",
    "        v_curr = nxt - curr\n",
    "        \n",
    "        num = torch.dot(v_prev, v_curr).item()\n",
    "        den = (torch.norm(v_prev).item() * torch.norm(v_curr).item()) + eps\n",
    "        \n",
    "        cos_val = num / den\n",
    "        cos_val = max(-1.0 + delta, min(1.0 - delta, cos_val))\n",
    "        \n",
    "        angle = math.acos(cos_val)\n",
    "        \n",
    "        total_angle += angle\n",
    "        count += 1\n",
    "        \n",
    "        prev, curr, v_prev = curr, nxt, v_curr\n",
    "    \n",
    "    return total_angle / max(count, 1)\n",
    "\n",
    "print('Curvature computation functions defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Measurement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_kappa(prompt: str, measure_layers: List[int], has_cot: bool = True) -> Tuple[Dict[int, float], int]:\n",
    "    \"\"\"\n",
    "    プロンプトに対してκを測定する。\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs['input_ids']\n",
    "    \n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    \n",
    "    if has_cot:\n",
    "        start_idx, end_idx = find_cot_token_range(input_ids, tokenizer)\n",
    "    else:\n",
    "        seq_len = input_ids.shape[1]\n",
    "        start_idx = seq_len // 2\n",
    "        end_idx = seq_len\n",
    "    \n",
    "    n_tokens = end_idx - start_idx\n",
    "    \n",
    "    kappa_by_layer = {}\n",
    "    for layer_idx in measure_layers:\n",
    "        # hidden_states[0]はembedding、hidden_states[i]はi層目の出力\n",
    "        actual_idx = min(layer_idx, len(hidden_states) - 1)\n",
    "        h = hidden_states[actual_idx][0, start_idx:end_idx, :]\n",
    "        h = h.float()\n",
    "        \n",
    "        kappa = compute_curvature_online(h)\n",
    "        kappa_by_layer[layer_idx] = kappa\n",
    "    \n",
    "    return kappa_by_layer, n_tokens\n",
    "\n",
    "\n",
    "# テスト\n",
    "if clean_traces_data and problems_data:\n",
    "    test_prob = problems_data[0]\n",
    "    test_trace = clean_traces_data[0]\n",
    "    test_prompt = create_prompt_with_cot(test_prob, test_trace['full_text'])\n",
    "    \n",
    "    print('Testing κ measurement...')\n",
    "    kappa_result, n_tok = measure_kappa(test_prompt, MEASURE_LAYERS, has_cot=True)\n",
    "    print(f'  n_tokens: {n_tok}')\n",
    "    print(f'  κ by layer: {kappa_result}')\n",
    "    print(f'  κ mean: {np.nanmean(list(kappa_result.values())):.4f}')\n",
    "    print('\\nTest successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Pilot (5 problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kappa_experiment(\n",
    "    problems: List[dict],\n",
    "    traces: Dict[int, dict],\n",
    "    max_problems: int = None\n",
    ") -> List[KappaResult]:\n",
    "    \"\"\"\n",
    "    全条件でκを測定する。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if max_problems:\n",
    "        problems = problems[:max_problems]\n",
    "    \n",
    "    for prob in tqdm(problems, desc='Problems'):\n",
    "        prob_idx = prob['index']\n",
    "        \n",
    "        if prob_idx not in traces:\n",
    "            continue\n",
    "        \n",
    "        trace_data = traces[prob_idx]\n",
    "        \n",
    "        for condition in CONDITIONS:\n",
    "            try:\n",
    "                if condition == 'direct':\n",
    "                    prompt = create_prompt_direct(prob)\n",
    "                    has_cot = False\n",
    "                elif condition == 'clean':\n",
    "                    prompt = create_prompt_with_cot(prob, trace_data['full_text'])\n",
    "                    has_cot = True\n",
    "                else:\n",
    "                    seed = derive_seed(GLOBAL_SEED, prob_idx, I=10, lam=CORRUPTION_LAMBDA)\n",
    "                    corrupted_cot = apply_corruption(trace_data, CORRUPTION_LAMBDA, seed)\n",
    "                    prompt = create_prompt_with_cot(prob, corrupted_cot)\n",
    "                    has_cot = True\n",
    "                \n",
    "                kappa_by_layer, n_tokens = measure_kappa(prompt, MEASURE_LAYERS, has_cot)\n",
    "                kappa_mean = np.nanmean(list(kappa_by_layer.values()))\n",
    "                \n",
    "                result = KappaResult(\n",
    "                    problem_index=prob_idx,\n",
    "                    condition=condition,\n",
    "                    kappa_by_layer=kappa_by_layer,\n",
    "                    kappa_mean=float(kappa_mean),\n",
    "                    n_tokens=n_tokens,\n",
    "                    timestamp=datetime.now().isoformat()\n",
    "                )\n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'\\nError for problem {prob_idx}, condition {condition}: {e}')\n",
    "        \n",
    "        if len(results) % (CHECKPOINT_EVERY * 3) == 0 and len(results) > 0:\n",
    "            save_json([asdict(r) for r in results], f'{SAVE_DIR_KAPPA}/checkpoints/latest_kappa_v3.1.json')\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# パイロット実行（5問）\n",
    "print('='*60)\n",
    "print('PILOT: Testing with 5 problems')\n",
    "print('='*60)\n",
    "\n",
    "pilot_results = run_kappa_experiment(problems_data, traces_dict, max_problems=5)\n",
    "\n",
    "# パイロット結果\n",
    "pilot_df = pd.DataFrame([asdict(r) for r in pilot_results])\n",
    "print('\\nPilot Results:')\n",
    "print(pilot_df.groupby('condition')['kappa_mean'].agg(['mean', 'std', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイロット結果を確認してから実行\n",
    "print('='*60)\n",
    "print('FULL EXPERIMENT')\n",
    "print('='*60)\n",
    "\n",
    "all_kappa_results = run_kappa_experiment(problems_data, traces_dict, max_problems=None)\n",
    "\n",
    "# 保存\n",
    "save_json([asdict(r) for r in all_kappa_results], f'{SAVE_DIR_KAPPA}/results/kappa_results_v3.1.json')\n",
    "print(f'\\nResults saved to: {SAVE_DIR_KAPPA}/results/kappa_results_v3.1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa = pd.DataFrame([asdict(r) for r in all_kappa_results])\n",
    "\n",
    "print('Kappa Results Summary:')\n",
    "print(df_kappa.groupby('condition')['kappa_mean'].agg(['mean', 'std', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 箱ひげ図\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "condition_order = ['direct', 'clean', 'corrupted']\n",
    "colors = ['#808080', '#2E8B57', '#DC143C']\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_kappa,\n",
    "    x='condition',\n",
    "    y='kappa_mean',\n",
    "    order=condition_order,\n",
    "    palette=colors,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Condition', fontsize=12)\n",
    "ax.set_ylabel('Mean Curvature (κ)', fontsize=12)\n",
    "ax.set_title('Hidden State Trajectory Curvature by Condition (Mistral 7B)', fontsize=14)\n",
    "\n",
    "means = df_kappa.groupby('condition')['kappa_mean'].mean()\n",
    "for i, cond in enumerate(condition_order):\n",
    "    if cond in means:\n",
    "        ax.annotate(f'μ={means[cond]:.3f}', xy=(i, means[cond]), xytext=(i+0.2, means[cond]),\n",
    "                    fontsize=10, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{SAVE_DIR_KAPPA}/figures/kappa_boxplot_v3.1.png', dpi=150)\n",
    "plt.show()\n",
    "print(f'Saved: {SAVE_DIR_KAPPA}/figures/kappa_boxplot_v3.1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計的検定\n",
    "from scipy import stats\n",
    "\n",
    "print('\\n=== Statistical Tests ===')\n",
    "\n",
    "clean_kappa = df_kappa[df_kappa['condition'] == 'clean']['kappa_mean'].dropna()\n",
    "corrupted_kappa = df_kappa[df_kappa['condition'] == 'corrupted']['kappa_mean'].dropna()\n",
    "\n",
    "if len(clean_kappa) > 0 and len(corrupted_kappa) > 0:\n",
    "    t_stat, p_val = stats.ttest_ind(clean_kappa, corrupted_kappa)\n",
    "    print(f'\\nClean vs Corrupted:')\n",
    "    print(f'  Clean mean: {clean_kappa.mean():.4f}')\n",
    "    print(f'  Corrupted mean: {corrupted_kappa.mean():.4f}')\n",
    "    print(f'  t-statistic: {t_stat:.4f}')\n",
    "    print(f'  p-value: {p_val:.4e}')\n",
    "    \n",
    "    if p_val < 0.05 and corrupted_kappa.mean() > clean_kappa.mean():\n",
    "        print('  ✓ Significant: Corrupted CoT has HIGHER curvature (as hypothesized)')\n",
    "    elif p_val < 0.05:\n",
    "        print('  ! Significant difference found, but direction unexpected')\n",
    "    else:\n",
    "        print('  - No significant difference detected')\n",
    "    \n",
    "    # Effect size\n",
    "    pooled_std = np.sqrt((clean_kappa.var() + corrupted_kappa.var()) / 2)\n",
    "    if pooled_std > 0:\n",
    "        cohens_d = (corrupted_kappa.mean() - clean_kappa.mean()) / pooled_std\n",
    "        print(f\"  Cohen's d: {cohens_d:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('KAPPA EXPERIMENT SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Version: {EXPERIMENT_VERSION}')\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Total measurements: {len(all_kappa_results)}')\n",
    "print(f'\\nMean κ by condition:')\n",
    "for cond in condition_order:\n",
    "    cond_data = df_kappa[df_kappa['condition']==cond]['kappa_mean']\n",
    "    if len(cond_data) > 0:\n",
    "        print(f'  {cond:12s}: {cond_data.mean():.4f} ± {cond_data.std():.4f}')\n",
    "print(f'\\nFiles saved to: {SAVE_DIR_KAPPA}')\n",
    "print('='*60)"
   ]
  }
 ]
}
